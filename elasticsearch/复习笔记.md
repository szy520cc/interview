## Elasticsearch 基本概念学习笔记
---

### **1. Elasticsearch (ES) 是什么？**
- **概念**  
  ES 是基于 Java 的开源分布式搜索引擎，基于 Lucene 构建，支持实时搜索、聚合分析和分布式存储。它既是搜索引擎，也是一种非关系型文档数据库（NoSQL）。
- **特点**  
  - **实时性**：通过定期刷新（Refresh）实现近实时搜索，默认刷新间隔为 1 秒（可通过 `refresh_interval` 调整）。刷新后数据从内存缓冲区写入文件系统缓存（生成新 Segment），即可被搜索。  
  - **分布式与扩展性**：横向扩展（分片和副本），支持 PB 级数据。  
  - **全文搜索**：支持高效的全文搜索功能，具有强大的搜索引擎 Lucene 作为后端。  
  - **RESTful API**：通过 HTTP/JSON 提供接口，支持多语言（Java、Python、Go 等）。  
  - **多语言支持**：处理结构化和非结构化数据。  
- **应用场景**  
  - 海量数据检索（如百度、京东站内搜索）。  
  - 日志分析（ELK 栈：ES + Logstash + Kibana）。  
  - 实时数据分析（如电商商品搜索、监控日志）。  

---

### **2. 全文检索原理**
- **核心概念**  
  - **分词（Tokenization）**：将文本拆分为词项（如 "ES is powerful" → ["ES", "is", "powerful"]）。  
  - **索引（Indexing）**：构建倒排索引（词项 → 文档ID列表）。  
  - **相关性排序**：使用 TF-IDF 或 BM25 算法计算文档与查询的相关性。  
- **优点**  
  - 高效性：通过索引快速定位文档。  
  - 相关性：根据词频、文档长度等因素排序。  
  - 灵活性：支持布尔查询、短语查询、模糊查询等。  
- **实现工具**  
  - ES、Apache Lucene（ES 核心组件）、Solr（基于 Lucene 的搜索平台）。  

---

### **3. ES 的基本构成**
- **Index（索引）**：存储数据的逻辑容器，类似数据库。  
- **Type（类型）**：ES 6.x 开始弃用，7.x 只允许一个类型 `_doc`，8.x 完全移除。  
- **Document（文档）**：最小数据单元，类似数据库的一行记录，支持动态字段。  
- **Field（字段）**：文档的最小单位，定义数据类型（如 `text`、`keyword`）。  
- **Shard（分片）**：将索引数据切分存储，支持横向扩展。  
  - **Primary Shard（主分片）**：索引创建时设置，通常不可修改（可通过 `_shrink`/`_split` API 调整，但需重建索引），默认 5 个。  
  - **Replica Shard（副本分片）**：可随时修改数量，默认 1 个。  
- **Replica（副本）**：只读副本，通过主分片同步数据，提供高可用和读负载均衡。  

---

### **4. 倒排索引（Inverted Index）**
- **概念**：关键词到文档 ID 的映射，是搜索引擎的核心数据结构。  
- **特点**：  
  - 词项按字典序升序排列。  
  - 支持快速定位包含关键词的文档。  

---

### **5. Mapping 与数据类型**
- **Mapping**：定义字段的结构（类似数据库表结构）。  
- **基本数据类型**：  
  - `text`（全文检索，分词）、`keyword`（精确匹配，不分词）、`date`、`integer`、`boolean` 等。  
- **复杂数据类型**：  
  - `object`（嵌套 JSON）、`nested`（独立索引的数组对象）。  
- **关键属性**：  
  - `index`：是否创建索引。  
  - `analyzer`：指定分词器（如 `standard`、`ik_smart`）。  
  - `fields`：多字段定义（如 `text` 和 `keyword` 共存）。  

---

### **6. `text` 与 `keyword` 的区别**
| **特性**         | **text**                          | **keyword**                      |
|------------------|-----------------------------------|----------------------------------|
| 分词             | 是（全文检索）                    | 否（精确匹配）                   |
| 使用场景         | `match` 查询、全文搜索            | `term` 查询、聚合、排序          |
| 大小写敏感       | 否（默认小写化）                  | 是（保留原始大小写）             |
| 截断长度         | 默认不截断                        | 超过 256 字符会被忽略索引        |

---

### **7. `query` 与 `filter` 的区别**
| **特性**         | **query**                          | **filter**                        |
|------------------|------------------------------------|-----------------------------------|
| 相关性评分       | 是（计算 `_score`）                | 否（不计算评分）                  |
| 缓存             | 否                                 | 是（默认缓存结果）                |
| 性能             | 较慢（需计算评分）                 | 快（仅过滤）                      |
| 使用场景         | 全文搜索、布尔查询                 | 精确过滤（如日期范围、布尔条件）  |

---

### **8. `term` 与 `match` 的区别**
- **`term`**：精确匹配（不分词），适用于 `keyword` 字段（如 ID、标签）。  
- **`match`**：全文检索（分词），适用于 `text` 字段（如商品描述）。  

---

### **9. ES 数据写入流程**
1. **客户端请求** → **协调节点（Coordinating Node）**。  
2. **路由**：根据文档 ID 哈希值确定主分片（Primary Shard）。  
3. **写入主分片**：写入内存缓冲区（Memory Buffer）和事务日志（Translog）。  
4. **同步副本**：主分片将数据复制到副本分片（Replica Shard）。  
5. **响应客户端**：所有分片写入成功后返回结果。  

---

### **10. 数据写入底层原理**
- **Refresh**：每秒将内存数据写入文件系统缓存（生成新 Segment 文件）。  
- **Flush**：每 30 秒或 Translog 超过 512MB 时，将数据持久化到磁盘。  
- **数据可靠性**：通过 Translog 防止宕机丢失数据。  

---

### **11. 数据更新与删除**
- **更新**：删除旧文档（标记为 `.del` 文件），插入新文档（新 `_version`），物理删除由 Segment Merge 完成。  
- **删除**：标记文档为删除状态，实际物理删除通过 Segment Merge 实现。  
- **Segment Merge**：合并小分片，清理被删除的文档。  

---

### **12. 搜索流程**
1. **Query 阶段**：协调节点广播查询到所有分片，各分片返回匹配文档的 ID 和排序值。  
2. **Fetch 阶段**：协调节点根据文档 ID 从对应分片获取完整数据，返回客户端。  

---

### **13. Master 节点选举**
- **Quorum 机制**：超过半数节点同意才能选举 Master，避免脑裂。  
- **选举逻辑**：集群启动或 Master 失效时，候选节点（`node.master: true`）通过心跳和投票选出最低 `node.id` 的节点。  
- **版本适配**：  
  - **ES 6.x**：设置 `discovery.zen.minimum_master_nodes = (master_nodes/2)+1`。  
  - **ES 7.0+**：配置 `cluster.initial_master_nodes` 明确指定初始 Master 节点列表。  

---

### **14. 脑裂问题与防范**
- **原因**：网络分区、节点故障、负载过高等导致多个 Master 节点。  
- **防范措施**：  
  - **ES 6.x**：设置 `minimum_master_nodes = (N/2)+1`。  
  - **ES 7.0+**：配置 `cluster.initial_master_nodes`。  
  - 合理配置副本和分片。  
  - 监控节点状态。  

---

### **15. 近实时性**
- **默认延迟**：1 秒（通过 `refresh_interval` 调整）。  
- **调优**：写入密集型场景可增大 `refresh_interval`（如 30s）以提升性能。  

---

### **16. 精准匹配与全文检索的区别**
- **精准匹配**：要求字段值完全一致（如 `term` 查询），适用于 `keyword` 字段。  
- **全文检索**：对查询词分词后匹配（如 `match` 查询），适用于 `text` 字段。  

---

### **17. ES 支持的查询类型**
- **精确匹配**：`term`、`range`、`prefix`、`wildcard`、`fuzzy` 等。  
- **全文检索**：`match`、`match_phrase`、`multi_match` 等。  

---

### **18. 数据分析器（Analyzer）**
- **Standard Tokenizer**：按空格和标点分词，转为小写。  
- **Keyword Tokenizer**：将整个文本视为一个词项（适用于精确匹配）。  
- **自定义 Analyzer**：结合分词器（Tokenizer）、过滤器（Filter）和字符过滤器（Char Filter）。  

---

### **19. MySQL 数据同步到 ES 的方式**
1. **同步双写**：应用层同时写入 MySQL 和 ES（强一致性，但性能差）。  
2. **异步双写**：通过消息队列（如 Kafka）异步同步（性能好，但可能丢失数据）。  
3. **数据抽取**：定时全量或增量抽取（如 Sqoop）。  
4. **数据订阅**：通过 Canal 订阅 MySQL 的 Binlog（实时增量同步）。  

---

### **20. 字典树（Trie）**
- **应用**：前缀查询（Prefix Query）和自动补全（Autocomplete）。  
- **特点**：O(k) 时间复杂度查找前缀匹配项（k 为前缀长度）。  

---

### **21. ES 与传统数据库的区别**
| **特性**         | **ES**                          | **传统数据库**                  |
|------------------|----------------------------------|----------------------------------|
| 事务支持         | 不支持 ACID                     | 支持 ACID                       |
| 查询语言         | JSON/DSL                        | SQL                             |
| 数据模型         | 文档型（JSON 格式）             | 关系型（表结构）                |
| 适用场景         | 全文搜索、实时分析              | 事务处理、复杂查询              |

---

### **22. ES 架构**
- **分布式架构**：节点分为 **主节点（Master Node）**、**数据节点（Data Node）**、**协调节点（Coordinating Node）**。  
- **分片与副本**：数据分片（Shard）和副本（Replica）保障高可用和性能。  

---

### **23. 性能调优技巧**
- **分片策略**：避免过多分片（增加管理开销），合理设置副本数。  
- **刷新间隔**：写入密集型场景增大 `refresh_interval`。  
- **字段过滤**：使用 `_source` 过滤非必要字段，减少网络传输。  
- **索引别名**：通过别名管理索引版本（如 `logs-2025-07` 和 `logs-2025-08`）。  

---

### **24. 常见面试题**
1. **ES 的近实时性如何实现？**  
   - 通过 `refresh_interval` 控制内存到文件系统缓存的刷新频率（默认 1 秒）。  

2. **如何避免脑裂？**  
   - **ES 6.x**：设置 `minimum_master_nodes = (N/2)+1`。  
   - **ES 7.0+**：配置 `cluster.initial_master_nodes`。  

3. **Text 和 Keyword 的使用场景？**  
   - `text` 用于全文搜索，`keyword` 用于聚合、排序和精确匹配。  

4. **ES 如何处理数据更新？**  
   - 删除旧文档（标记为 `.del` 文件），插入新文档（新 `_version`）。  

5. **如何优化 ES 的写入性能？**  
   - 增大 `refresh_interval`、批量写入（Bulk API）、减少副本数。  

---

### **25. 补充知识点**
- **索引别名（Alias）**：用于管理索引版本切换和跨索引查询。  
- **冷热数据分离**：热数据（高频访问）存储在 SSD，冷数据（低频访问）存储在磁带。  
- **滚动索引（Rolling Index）**：按时间或大小创建新索引（如 `logs-2025-07`）。  

---

### **26. 总结**
Elasticsearch 是分布式搜索引擎，适用于海量数据的实时检索和分析。掌握其核心概念（如倒排索引、分片、副本）、原理（如写入流程、搜索机制）和调优技巧是面试重点。实际应用中需根据场景选择合适的数据类型（`text` vs. `keyword`）、查询方式（`query` vs. `filter`），并合理配置分片和副本以保证高可用性。