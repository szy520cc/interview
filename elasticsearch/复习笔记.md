## ES是什么
### 概念
+ ES是由 **java **语言开发的基于 **Lucene **的一款开源的存储，搜索，聚合分析的**全文搜索引擎**。同时它也可以称为一种**非关系型文档数据库**

### 特点
+ 实时搜索和分析
    - ES 能够快速处理数据，PB级数据下提供近实时的搜索和分析能力。
+ 分布式和可扩展
    - ES 是一个分布式系统，通过横向扩展，增加节点来提高存储和处理大量数据的能力。
+ 全文搜索
    - 支持高效的全文搜索功能，具有强大的搜索引擎 Lucene 作为后端。
    - 提供丰富的查询语言和搜索功能，如模糊搜索、短语查询、等值查询、范围查询等。
+ RESTful API
    - 通过 HTTP 和 JSON 提供易用的 RESTful API，方便其他语言调用。
+ 多语言支持
    - 几乎支持所有的主流编程语言，处理结构化和非结构化数据。

### 应用场景
+ 海量数据的全文检索，搜索引擎，垂直搜索，站内搜素
    - 百度，谷歌，CSDN，知网为代表海量数据的全文检索
    - 以京东，淘宝为代表的垂直搜索
+ 数据分析和聚合查询
+ 日志系统：ELK （ES + Logstash + Kibana）
    - Logstash 
        * 是一个强大的数据处理管道，可以从多个来源接收数据，进行处理和转发。
        * 主要功能
            + 接收多种格式的信息（如日志文件、数据库、消息队列等）。
            + 进行数据转换和处理，例如格式化、过滤和增强数据。
            + 将处理后的数据输出到 ES、文件或其他存储系统。
    - Kibana
        * Kibana 是一个用于数据可视化的工具，主要与 ES 结合使用。
        * 主要功能
            + 提供强大的可视化组件，帮助用户创建图表、仪表板和报表。
            + 通过图形界面方便地查询和分析数据。
            + 实现实时数据监控和可视化，支持交互式探索数据。

## <font style="color:rgb(25, 27, 31);">什么是全文检索</font>
### 基本概念
+ **全文检索**（Full-Text Search）是指在一个文档集合中根据关键词或短语查找目标文档的搜索过程。与传统数据库中的查询不同，全文检索不仅仅是对字符串进行精确或模糊匹配，而是通过复杂的算法和数据结构来提高搜索的效率和计算相关性。

### 核心概念
#### 分词（Tokenization）
+ 全文检索的第一步是将文本内容进行分词。分词的目的是将连续的字符串转换为词项字典，便于后续的索引和搜索。
+ 例如，文本 “ES is powerful” 可能会被分词为 [“ES”, “is”, “powerful”]。

#### 索引（Indexing）
+ 创建索引是将文档内容中的词项映射到一个数据结构中，以便能够快速查找包含这些词语的文档。
+ 常用的索引结构包括倒排索引（Inverted Index），建立词语与包含该词语的文档id之间的映射关系。

#### 相关性排序（Relevance Scoring）
+ 相关性排序是根据查询和文档之间的相似度来对结果进行排序的过程。常见的评分算法包括 TF-IDF（Term Frequency-Inverse Document Frequency）和 BM25。
+ 例如，查询 “ES” 更倾向于返回包含该词频繁出现的文档，且这些文档在整个文档集合中较为罕见。

### 全文检索的优点
+ **高效性：**通过索引和优化的数据结构，全文检索能够快速定位包含查询词的文档。
+ **相关性：**全文检索不仅仅是简单的字符串匹配，它能够根据词语的频率、文档的长度和词语的分布等因素来排序结果。
+ **灵活性：**支持复杂的查询语法，如布尔查询、短语查询、模糊查询、近似查询等。

### 应用场景
+ **搜索引擎：**如 Google、Baidu，它们通过全文检索技术来处理海量的网页数据，并返回最相关的结果。
+ **文档管理系统：**企业内部的文档管理系统可以使用全文检索来快速查找存储的文档。
+ **电子商务：**在线商城可以使用全文检索来帮助用户查找商品。

### 实现工具
+ ES<font style="color:rgb(36, 41, 47);">：一个开源的分布式搜索和分析引擎，广泛用于全文检索、日志分析、实时数据分析等。</font>
+ **<font style="color:rgb(36, 41, 47);">Apache Lucene</font>**<font style="color:rgb(36, 41, 47);">：一个高性能的全文检索库，是 ES 的核心组件。</font>
+ **<font style="color:rgb(36, 41, 47);">Solr</font>**<font style="color:rgb(36, 41, 47);">：一个基于 Apache Lucene 的开源搜索平台，适用于大规模的搜索应用。</font>

### 总结
+ 全文检索是一种强大的搜索技术，通过分词、索引和评分等步骤，能够高效地从大量文本数据中找到相关信息。它在搜索引擎、文档管理、电子商务等领域有着广泛的应用。理解全文检索的核心概念和实现工具，对于开发和优化搜索应用非常重要。

## ES的基本构成
### Index索引
+ 索引类似于mysql 中的数据库，Elasticesearch 中的索引是存储数据的地方，index包含了一堆具有相似结构的文档数据

### Type类型
+ 类型是用来定义数据结构的，类似于mysql中数据表的概念，type 是 index 中的一个逻辑数据分类
+ 从 ES 6.x 版本开始，官方逐渐弃用了类型的使用。在 ES 7.x 版本中，每个索引只能包含一个类型，并且类型的名称被固定为 _doc。在 ES 8.x 版本中，类型已被完全移除

### document 文档
+ 类似于 MySQL 中的一行数据，不同之处在于 ES 中的每个文档可以有不同的字段，但是对于通用字段应该具有相同的数据类型，文档是es中的最小数据单元，可以认为一个文档就是一条记录。

### Field 字段
+ Field是ES的最小单位，一个document里面有多个field。

### shard分片
+ 单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。有了shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。

### replica副本  
+ 任何一个服务器随时可能故障或宕机，此时主shard 可能会丢失，因此可以为每个 shard 创建多个 replica 副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），默认每个索引10个 shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器。

## 什么是倒排索引
### 概念   
+ 倒排索引（Inverted Index）是一种用于全文检索的高效数据结构，它允许快速检索包含特定关键词的文档。倒排索引是大多数搜索引擎（包括 ES）使用的核心技术之一。
+ 在搜索引擎中，每个文档都有一个对应的文档 ID，文档内容被表示为一系列关键词的集合。文档在索引过程中，Es会对文档内容进行分词（Tokenize）和过滤（Filter），生成多个单词（Term），每个关键词都会记录它在文档中出现的次数及位置。那么，倒排索引就是 关键词到包含该关键词的文档 ID 的映射关系，每个关键词都对应着一系列的文档id，这些文档中都出现了该关键词。

### 倒排索引的两个重要细节：
+ 倒排索引中的所有词项对应一个或多个文档，这些文档中都出现了该词项
+ 倒排索引中的词项根据字典顺序升序排列

## Mapping是什么? Es有那些数据类型
### 概念
+ <font style="color:rgb(25, 27, 31);">ES 中的 Mapping 也称之为</font>**<font style="color:rgb(25, 27, 31);">映射</font>**<font style="color:rgb(25, 27, 31);">有点类似于</font>[<font style="color:rgb(25, 27, 31);">关系型数据库</font>](https://zhida.zhihu.com/search?content_id=238224540&content_type=Article&match_order=1&q=%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93&zhida_source=entity)<font style="color:rgb(25, 27, 31);">中“表结构”的概念，在 MySQL 中，表结构里包含了字段名称，字段的类型还有索引信息等。在 Mapping 里也包含了一些属性，比如字段名称、数据类型、字段使用的分词器、是否评分、是否创建索引等属性。</font>

以下是 **Elasticsearch 的 Mapping** 和 **MySQL 表结构** 的对比表格，涵盖字段、索引、数据类型、灵活性等方面的核心差异：

| **对比维度**       | **Elasticsearch Mapping**                                                                 | **MySQL 表结构**                                                                 |
|--------------------|------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|
| **定义方式**       | 动态映射（自动推断字段类型）或手动定义映射（JSON 格式）。                                 | 需要显式定义表结构（DDL 语句），字段类型和约束必须提前定义。                     |
| **字段类型**       | 支持丰富的数据类型（如 `text`、`keyword`、`integer`、`date`、`nested` 等），且可自定义类型。 | 预定义的数据类型（如 `INT`、`VARCHAR`、`DATE`、`TEXT` 等），类型固定。           |
| **分词器（Analyzer）** | 映射中可指定字段的分词器（如 `standard`、`ik_max_word`），影响搜索和索引行为。             | 全文索引依赖分词（如 `ngram` 或 `MyISAM` 的 `full-text` 分词），但灵活性较低。     |
| **索引机制**       | 默认为字段创建倒排索引，支持动态配置是否存储（`store`）、是否索引（`index`）等属性。         | 需手动创建索引（如 `PRIMARY KEY`、`UNIQUE`、`INDEX`），索引与字段分离。           |
| **动态映射**       | 支持动态映射（`dynamic` 模式），可自动推断新字段的类型。                                   | 不支持动态映射，所有字段必须显式定义。                                           |
| **嵌套数据**       | 支持嵌套对象（`nested` 类型）和数组（`array` 类型），天然适合非结构化数据。                 | 需通过关联表或 JSON 类型（如 `JSON` 字段）处理嵌套数据，复杂度较高。              |
| **查询方式**       | 使用 DSL 查询（如 `match`、`term`、`range`），支持全文搜索和复杂组合查询。                 | 使用 SQL 查询（`SELECT`、`JOIN`、`WHERE`），更适合结构化查询。                   |
| **数据存储**       | 数据以 JSON 文档形式存储，字段可动态扩展。                                                 | 数据以行和列的形式存储，字段数量和类型固定。                                     |
| **性能优化**       | 通过 `fielddata` 或 `keyword` 类型优化聚合查询性能，支持分片和副本提升扩展性。               | 通过索引、分区和查询优化（如 `EXPLAIN`）提升性能，但扩展性受限于单机性能。         |
| **事务支持**       | 不支持 ACID 事务（适合读多写少的场景）。                                                  | 支持 ACID 事务（适合写多读少或强一致性场景）。                                    |
| **一致性模型**     | 最终一致性（适合高并发写入和近实时搜索）。                                                | 强一致性（适合严格事务场景）。                                                   |
| **适用场景**       | 实时搜索、日志分析、非结构化数据存储（如商品信息、用户行为日志）。                        | 传统关系型数据管理（如订单、用户表、库存管理）。                                 |

---

### **核心差异总结**
1. **灵活性**：  
   - **Elasticsearch**：动态映射、嵌套数据支持、灵活的字段类型，适合处理非结构化或半结构化数据。  
   - **MySQL**：严格的表结构定义，适合结构化数据管理。  

2. **查询能力**：  
   - **Elasticsearch**：强大的全文搜索和复杂 DSL 查询，适合实时分析。  
   - **MySQL**：SQL 查询优化成熟，适合事务性和关联查询。  

3. **扩展性**：  
   - **Elasticsearch**：水平扩展能力强，适合大规模分布式场景。  
   - **MySQL**：垂直扩展为主，分布式方案（如分库分表）复杂度高。  

4. **一致性**：  
   - **Elasticsearch**：最终一致性，适合高可用和高写入吞吐量。  
   - **MySQL**：强一致性，适合金融级事务场景。  

---

### **示例代码对比**
#### **Elasticsearch Mapping 定义**
```json
{
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "ik_max_word"
      },
      "price": {
        "type": "float",
        "index": false
      },
      "tags": {
        "type": "keyword"
      }
    }
  }
}
```

#### **MySQL 表结构定义**
```sql
CREATE TABLE products (
  id INT PRIMARY KEY AUTO_INCREMENT,
  title VARCHAR(255),
  price DECIMAL(10, 2),
  tags TEXT
);
```

---

通过以上对比，可以看出 **Elasticsearch Mapping** 更适合非结构化数据的搜索和分析，而 **MySQL 表结构** 更适合传统关系型数据管理。

### 查看mapping
```plain
//查看索引完整的mapping
GET /my_index/_mappings
//查看索引指定字段的mapping
GET /my_index/_mappings/field/field_name
```

### 数据类型
#### 基本的数据类型
+ Text：用于全文搜索的字符串，会被分词。
+ Keyword：用于精确匹配的字符串，不会被分词。
+ Date：日期类型。
+ Integer、Long、Short、Byte：不同精度的整数。
+ Float、Double：不同精度的浮点数。
+ Boolean：布尔类型。
+ Binary：二进制数据。

#### 复杂数据类型
+ **<font style="color:rgb(36, 41, 47);">Object</font>**<font style="color:rgb(36, 41, 47);">：表示 JSON 对象，可以包含其他字段和类型。</font>
+ **<font style="color:rgb(36, 41, 47);">Nested（嵌套类型）</font>**<font style="color:rgb(36, 41, 47);">：用于处理数组中的对象，使其能够独立索引。</font>

### Mapping 的关键属性
+ 在定义字段的 mapping 时，可以指定一些关键属性来控制字段的行为：

#### index
控制该字段是否被索引。如果设置为 **false**，该字段将不会被搜索到。

```plain
"email": {
  "type": "keyword",
  "index": false
}
```

#### analyzer
+ 指定字段的分析器，用于全文字段的分词。

```plain
"biography": {
  "type": "text",
  "analyzer": "english"
}
```

#### format
+ 用于 **date** 类型的字段，定义日期格式

```plain
"join_date": {
  "type": "date",
  "format": "yyyy-MM-dd"
}
```

#### fields
+ 允许你在一个字段下定义多个子字段。每个子字段可以拥有不同的数据类型或分析器。常见的使用场景包括
    - 对一个字段同时支持 **全文搜索** 和 **精确匹配**
    - 对一个字段使用不同的**语言分析器**
    - 对一个字段进行**不同方式的索引**，以便支持多种查询需求

```plain
PUT /my_index
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
```

## Text & Keyword 数据类型的区别
### Text
<font style="color:rgb(25, 27, 31);">设置为 </font>**<font style="color:rgb(25, 27, 31);">text </font>**<font style="color:rgb(25, 27, 31);">类型的字段，在存入 ES 时，字段内容会被分词、过滤、大小写转换，根据分词后的内容建立倒排索引</font>

**<font style="color:rgb(25, 27, 31);">注意事项</font>**

+ <font style="color:rgb(25, 27, 31);">适用于全文检索：如 match 查询。</font>
+ <font style="color:rgb(25, 27, 31);">文本字段会被分词。</font>
+ <font style="color:rgb(25, 27, 31);">默认情况下，会创建倒排索引。</font>
+ <font style="color:rgb(25, 27, 31);">自动映射器会为 Text 类型创建 Keyword 字段。</font>

![](https://cdn.nlark.com/yuque/0/2024/webp/49727441/1729441530374-57feeffa-cb2a-4138-b174-65af232c031d.webp)

### Keyword
+ keyword 类型的字段内容是不会分词的，直接根据字符串内容建立倒排索引，keyword类型的字段只能通过精确值搜索到
+ 当使用 Keyword 类型查询时，其字段值会被作为一个整体，并保留字段值的原始属性。

```plain
GET index/_search
{
  "query": {
    "match": {
      "title.keyword": "测试文本值"
    }
  }
}
```

+ <font style="color:rgb(25, 27, 31);">Keyword 不会对文本分词，会保留字段的原有属性，包括大小写等。</font>
+ <font style="color:rgb(25, 27, 31);">Keyword 仅仅是字段类型，而不会对搜索词产生任何影响。</font>
+ <font style="color:rgb(25, 27, 31);">Keyword 一般用于需要精确查找的字段，或者聚合排序字段。</font>
+ <font style="color:rgb(25, 27, 31);">Keyword 通常和 Term 搜索一起用。</font>
+ <font style="color:rgb(25, 27, 31);">Keyword 字段的 </font>`<font style="color:rgb(25, 27, 31);background-color:rgb(248, 248, 250);">ignore_above</font>`<font style="color:rgb(25, 27, 31);"> 参数代表其截断长度，默认 256，如果超出长度，字段值会被忽略，而不是截断，忽略指的是会忽略这个字段的索引，搜索不到，但数据还是存在的。</font>

## query 和 filter 的区别
#### <font style="color:rgb(36, 41, 47);">作用</font>
+ query
    - 用于计算文档与查询条件的相关性分数，找出与查询条件最匹配的文档，并根据相关性进行排序。
+ filter
    - 用于精确匹配文档，通常用于过滤掉不符合条件的文档，筛选出符合特定条件的文档，不关心这些文档与查询条件的相关性。

### <font style="color:rgb(36, 41, 47);">相关性分数</font>
+ query
    - 查询时会计算相关性分数（_score），分数越高表示文档与查询条件越匹配。
    - 查询结果按相关性分数排序（降序）。
+ filter
    - 过滤时不计算相关性分数，只检查文档是否满足条件。
    - 查询结果不会按相关性排序。

### <font style="color:rgb(36, 41, 47);">缓存和性能</font>
+ query
    - 查询通常不缓存结果。
    - 计算相关性分数需要更多资源，查询速度相对较慢。
+ filter
    - 过滤结果通常会被缓存（如果 cache 参数设置为 true），后续相同的过滤查询可以快速返回结果。
    - 不需要计算相关性分数，查询速度较快。

### <font style="color:rgb(36, 41, 47);">使用场景</font>
+ query
    - 用于需要根据相关性排序的场景，如全文搜索、布尔查询、短语查询等。
    - 示例：查找包含关键词“ES”且相关性分数最高的文档。
+ filter
    - 用于精确匹配和筛选，如日期范围、数值范围、布尔条件等。
    - 示例：查找在特定日期范围内创建的文档。

### 总结
+ query
    - 用于计算相关性分数，并根据相关性排序结果。
+ filter
    - 用于精确匹配和筛选文档，不计算相关性分数，速度更快，结果可以被缓存。

## term与match之间的区别
### term
+ 精确匹配：term 查询用于精确匹配字段的内容，不进行分词。它适用于关键词与字段值精确匹配，比如数值、日期、布尔值或者不需要分词的字符串（如ID、邮政编码）。
+ 不分词：如果查询的字段是文本类型，term 查询不会对查询字符串进行分词，而是直接匹配整个词。例如，查询"user":"John Doe"时，它只会匹配整个字段为“John Doe”的文档，而不会匹配包含“John”或“Doe”的文档。

### match
+ 全文检索：match 查询用于全文检索，它会对查询的文本进行分词，然后搜索这些分词的匹配。适用于自然语言文本的搜索。
+ 分词匹配：对于文本类型的字段，match 查询会将输入的字符串分成多个词条，然后搜索与这些词条匹配的文档。例如，查询"user":"John Doe"时，它会将字符串分词为“John”和“Doe”，然后搜索包含这两个词的文档。

## ES 索引数据过程
+ 客户端请求发送
    - 客户端选择 Es 集群中的一个节点，发送写入请求。这一节点被称为 coordinating node（协调节点）。协调节点可以是任何一个节点，不必是主节点。
+ 请求路由
    - 协调节点接收到请求后，对文档进行路由，将请求转发给对应的 node。这是通过计算文档的哈希值，来确定文档应该存储到哪个 primary shard（主分片）。
    - Routing 的逻辑是通过文档 ID（如果有提供）或默认的路由规则进行的。通过这些策略，ES 确保数据均匀分布在各个 shards 上。
+ 处理请求
    - Primary shard（主分片）接收到请求后，会执行如下操作：
        * 将文档索引到该主分片中。这涉及到创建或更新倒排索引。
        * 数据在主分片内成功处理后，主分片会将数据变更同步到其关联的 replica shards（副本分片）。这一步确保数据的冗余和高可用性。
        * 副本分片接收到数据后，会重复相同的索引过程，以确保主从分片数据一致。
+ 响应结果：
    - 当协调节点收到主分片和所有副本分片的成功响应后，才会返回结果给客户端。（这确保了写操作的成功性，将最终一致性提供给调用者。）
    - 如果在此过程中出现任何错误（例如，副本分片未能成功写入），协调节点将会考虑写入操作失败并返回相关错误信息。
+ 总结如下：
    - 客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node （协调节点）
    - coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）
    - 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node
    - coordinating node 等到 primary node 和所有 replica node 都执行成功之后，返回响应结果给客户端。

## 索引数据的底层原理
![](https://cdn.nlark.com/yuque/0/2024/jpeg/49727441/1729510561367-349c722c-cad3-44e4-ade4-5aac2c29a7ae.jpeg)

### 索引过程
1. 数据先写入 memory buffer，然后定时（默认每隔1s）将 memory buffer 中的数据写入一个新的 segment 文件中，并进入 Filesystem cache（同时清空 memory buffer），这个过程就叫做 refresh； 
2. 由于 memory Buffer 和 Filesystem Cache 都是基于内存，假设服务器宕机，那么数据就会丢失，所以 ES 通过 translog 日志文件来保证数据的可靠性，在数据写入 memory buffer 的同时，将数据写入 translog 日志文件中，在机器宕机重启时，es 会自动读取 translog 日志文件中的数据，恢复到 memory buffer 和 Filesystem cache 中去。
3. flush 操作：不断重复上面的步骤，translog 会变得越来越大，当 translog 文件默认每30分钟或者阈值超过 512M 时，就会触发 commit 操作，即 flush操作。将 buffer 中的数据 refresh 到 Filesystem Cache 中去，清空 buffer；创建一个新的 commit point（提交点），同时强行将 Filesystem Cache 中目前所有的数据都 fsync 到磁盘文件中；
4. 删除旧的 translog 日志文件并创建一个新的 translog 日志文件，此时 commit 操作完成

### ES 的近实时性：  
+ 数据存在 memory buffer 时是搜索不到的，只有数据被 refresh 到 Filesystem cache 之后才能被搜索到，而 refresh 是每秒一次， 所以称 es 是近实时的，可以通过手动调用 es 的 api 触发一次 refresh 操作，让数据马上可以被搜索到。

### ES 数据丢失的问题：
+ translog 也是先写入 Filesystem cache，然后默认每隔 5 秒刷一次到磁盘中，所以默认情况下，可能有 5 秒的数据会仅仅停留在 memory buffer 或者 translog 文件的 Filesystem cache中，而不在磁盘上，如果此时机器宕机，会丢失 5 秒钟的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。

## <font style="color:rgba(0, 0, 0, 0.9);">ES更新和删除文档</font>
### 概念
+ 更新和删除都是写操作，但是由于 ES 中的文档是不可变的，因此不能被修改或删除以展示其变更；磁盘上的每个段都有一个相应的.del 文件，所以 ES 利用 .del 文件标记文档是否被删除。 

#### 删除操作
+ 文档并没有真的被删除，而是在 .del 文件中被标记为 deleted 状态。该文档依然能匹配查询，但是会在结果中被过滤掉。

#### 更新操作
+ 将旧的 doc 标识为 deleted 状态，然后创建一个新的 doc。

### segment merge
+ memory buffer 每 refresh 一次，就会产生一个 segment 文件 ，所以默认情况下是 1s 生成一个 segment 文件，这样下来 segment 文件会越来越多，此时会定期执行 merge。
+ 每次 merge 的时候，会将多个 segment 文件合并成一个，同时会将标识为 deleted 的 doc 进行物理删除，不会写入到新的 segment 中，然后将新的 segment 文件写入磁盘，这里会写一个 commit point ，标识所有新的 segment 文件，然后打开 segment 文件供搜索使用，同时删除旧的 segment 文件

## ES的搜索流程
+ 搜索被执行成一个两阶段过程，即 Query Then Fetch (先查询后取回)：

### Query阶段：
+ 客户端发送请求到 coordinate node，协调节点将搜索请求广播到所有的 primary shard 或 replica shard。
+ 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。
+ 每个分片返回各自优先队列中所有文档的 ID 和排序值 给协调节点。
+ 由协调节点进行数据的合并、排序、分页等操作，产出最终结果。

### Fetch阶段：
+ 协调节点根据 **doc id** 去各个节点上查询实际的 document 数据，由协调节点返回结果给客户端。
+ 协调节点 对 **doc id** 进行 **哈希路由**，将请求转发到对应的 node，此时会使用 round-robin 随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。
+ 接收请求的 node 返回 document 给 coordinate node 。
+ coordinate node 返回 document 给客户端。
+ Query Then Fetch 的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch 增加了一个预查询的处理，询问 Term 和 Document frequency，这个评分更准确，但是性能会变差。

## <font style="color:rgba(0, 0, 0, 0.9);">ES如何选举Master节点</font>
### ES 的分布式原理
+ ES 会对存储的数据进行切分，将数据划分到不同的分片上，同时每一个分片会保存多个副本，主要是为了保证分布式环境的高可用。在 ES 中，节点是对等的，节点间会选取集群的 Master，由 Master 负责集群状态信息的改变，并同步给其他节点。

### ES 的写入性能会不会很低？
+ 只有建立索引和类型需要经过 Master，数据的写入有一个简单的 Routing 规则，可以路由到集群中的任意节点，所以数据写入压力是分散在整个集群的。

### ES 如何选举 Master？
在 ES 中，Master 节点负责管理整个集群的状态，包括创建/删除索引、分配分片、管理节点等，不负责文档级别的管理。为了保证集群的高可用性，ES 实现了自动的 Master 选举机制。当当前的 Master 节点不可用时，集群会自动从其他节点中选举出一个新的 Master 节点。

#### <font style="color:rgb(36, 41, 47);background-color:rgb(248, 248, 248);">集群启动时选举</font>
+ 当 ES 集群启动时，所有节点都会加入到集群中。
+ 如果集群中还没有 Master 节点，集群中的所有 Master 候选节点（配置了 node.master: true 的节点）会参与选举。
+ 这些节点通过 Zen Discovery 机制相互通信，进行投票，选出拥有最低 node.id 的节点作为新的 Master 节点。
+ Zen Discovery 机制通过节点间的定期 Ping 和心跳操作，确保了 ES 集群中节点的互相发现、状态同步和 Master 节点的选举。通过这种机制，ES 能够有效地管理集群的变化，保证其高可用性和一致性。 

#### Master 节点失效时的重新选举：
+ 如果当前的 Master 节点由于某种原因（如节点故障、网络分区等）不可用，集群中的其他 Master 候选节点 会检测到这一情况。
+ Master 候选节点通过 **Ping操作 **和 **心跳 **来互相通信，确认当前的 Master 是否存活。如果大多数节点认为当前 Master 已经失效，则开始新的选举。
+ 候选节点之间通过交换彼此的节点信息，并通过投票选出新的 Master 节点，通常是拥有最低 node.id 的节点。

#### 确保选举的正确性（Quorum 机制）：
+ 为了避免脑裂问题（即同时存在多个 Master 节点，导致集群状态不一致），ES 使用 Quorum（法定人数）机制。
+ 只有在大多数（超过一半）的 Master 候选节点 达成一致时，才会进行 Master 选举。这意味着如果集群中的候选节点数不足，集群将无法选举新的 Master，以保护数据一致性。
+ 可以通过配置 discovery.zen.minimum_master_nodes 来设置需要多少个节点才能构成法定人数。这个值通常应该设置为 (N/2) + 1，其中 N 是候选节点的总数。

## Quorum 机制（法定人数）
Quorum 机制是一种分布式系统中用于确保数据一致性的协议。它通常用于像区块链这样的去中心化网络中，以确保在多个节点间达成一致。**Quorum 机制的核心思想是通过多数决来决定最终的结果，即只有当超过半数的节点（通常是大多数节点）同意某一决策或数据状态时，该决策或状态才被认为是有效的**。

### Quorum 机制的主要特点：
+ 多数决原则
    - 在分布式系统中，Quorum 机制通常要求大多数节点（如超过半数的节点）对某一事务达成一致意见。这个多数可以是简单的多数（如超过半数），也可以是特定的阈值（如三分之二），具体取决于系统的设计。
+ 数据一致性
    - Quorum 机制确保了数据的一致性，避免了“脑裂”（split-brain）现象，即网络被分割成两个或多个部分，每个部分认为自己代表了整个网络。
+ 容错性
    - 由于 Quorum 机制依赖于多数节点的同意，系统可以容忍一定数量的节点故障（通常是少于一半）而不影响系统的正常运行。
+ 灵活性
    - Quorum 机制可以根据实际需求进行调整，比如选择不同的多数阈值（如三分之二、四分之三等），以满足不同场景下的容错和性能需求。

### <font style="color:rgb(36, 41, 47);">应用场景</font>
+ 区块链
    - 在区块链网络中，Quorum 机制用于确保交易和区块的有效性。只有当大多数节点确认一个区块时，该区块才会被添加到区块链中。
+ 分布式数据库
    - 在分布式数据库系统中，Quorum 机制用于确保数据的读写一致性。例如，在选主（leader election）过程中，Quorum 机制确保只有一个主节点被选出。

### 总结
Quorum 机制是分布式系统中保障数据一致性和系统容错性的重要手段。通过依赖多数节点的同意，Quorum 机制能够在复杂的网络环境中确保系统的高可用性和数据可靠性。

## 脑裂问题
### 概念
脑裂是指网络中的节点因为某种原因（如网络故障、节点崩溃等）分为两个或多个群体，导致这些群体之间无法通信。在这种情况下，各个群体可能会继续操作并产生各自的状态，最终导致数据的不一致。

简单说：ES中的所有节点并未形成一个完整的集群，或者形成若干个小集群，遇到过两种情况：

+ 形成多个小集群，有多个master；
+ 有一个master，但是集群中节点的个数 和 ES节点个数不一致；

### <font style="color:rgb(36, 41, 47);">产生原因</font>
+ **<font style="color:rgb(36, 41, 47);">网络延迟：</font>**<font style="color:rgb(36, 41, 47);"> 选举master时，网络延迟导致有些节点并没有加入到集群。</font>
+ **<font style="color:rgb(36, 41, 47);">节点故障：</font>**<font style="color:rgb(36, 41, 47);"> 某个节点或多个节点崩溃，导致其不能参与选举。</font>
+ **<font style="color:rgb(36, 41, 47);">故障恢复或重启：</font>**<font style="color:rgb(36, 41, 47);"> 节点重启后可能不清楚之前的状态，导致无法参与选举。</font>
+ **<font style="color:rgb(36, 41, 47);">负载过大</font>**<font style="color:rgb(36, 41, 47);">：当一个节点同时作为master节点和数据节点，若数据传输较大或索引较大，处理时间长造成节点长时间没有响应，可能被其他节点认为失效，从而重新选举。</font>

### <font style="color:rgb(36, 41, 47);">影响</font>
+ **数据不一致性： **由于不同主节点可能会接受写入操作，导致数据在各个分区间不一致。
+ **数据丢失：**当集群恢复同步时，可能会出现数据丢失或数据覆盖的风险。

### 防范措施
+ **<font style="color:rgb(36, 41, 47);">主节点选举：</font>**<font style="color:rgb(36, 41, 47);"> 使用基于 Quorum 的算法确保始终存在一个主节点。在选举过程中，要求大多数节点参与投票，以确保只有一个master节点。</font>
+ **<font style="color:rgb(36, 41, 47);">分片副本机制：</font>**<font style="color:rgb(36, 41, 47);"> ES 使用分片和副本来增强容错能力。如果某个节点失效，其他副本可以用来继续提供服务。</font>
+ **<font style="color:rgb(36, 41, 47);">设置集群的最小篇幅（minimum_master_nodes）：</font>**<font style="color:rgb(36, 41, 47);"> </font><font style="color:rgb(36, 41, 47);">通过设置集群的最小主节点数目，可以避免脑裂情况。建议配置为</font><font style="color:rgb(36, 41, 47);"> </font>`<font style="color:rgb(71, 101, 130);">(N / 2) + 1</font>`<font style="color:rgb(36, 41, 47);">，其中 N 是集群中节点的总数。</font>
+ **<font style="color:rgb(36, 41, 47);">监控和告警：</font>**<font style="color:rgb(36, 41, 47);"> 实施监控以检测网络分区和节点故障并及时处理。</font>

## 怎么理解ES的 近实时
+ 从文档索引（写入）到可搜索到之间的延迟默认一秒钟，因此ES是近实时（NRT）搜索平台。
+ 也就是说：文档写入，最快一秒钟被索引到，不能再快了。
+ 写入调优的时候，我们通常会动态调整：refresh_interval = 30s 或者更大值，以使得写入数据更晚一点时间被搜索到。

## 精准匹配检索和全文检索的区别
### <font style="color:rgb(36, 41, 47);">精准匹配检索</font>
+ **特点**
    - **<font style="color:rgb(36, 41, 47);">精确性</font>**<font style="color:rgb(36, 41, 47);">：要求检索词与文档中的字段值完全一致。</font>
    - **<font style="color:rgb(36, 41, 47);">适用场景</font>**<font style="color:rgb(36, 41, 47);">：常用于需要精确匹配的场景，如idcard、用户名、商品编号、唯一标签等。</font>
+ **<font style="color:rgb(36, 41, 47);background-color:rgb(248, 248, 248);">实现机制</font>**
    - **<font style="color:rgb(36, 41, 47);">关键词匹配</font>**<font style="color:rgb(36, 41, 47);">：检索词对比字段值，必须完全相同才视为匹配。</font>
    - **<font style="color:rgb(36, 41, 47);">字段类型</font>**<font style="color:rgb(36, 41, 47);">：适用于精确值字段，如 </font>`<font style="color:rgb(71, 101, 130);">keyword</font>`<font style="color:rgb(36, 41, 47);"> 类型字段。</font>

```plain
{
  "query": {
    "term": {
      "user_id": "12345"
    }
  }
}
```

### 全文检索
+ **特点：**
    - **语义分析：**全文检索会对检索词进行分析，包括分词和语义处理，以找到最相关的文档。
    - **灵活性：**能够处理模糊查询、同义词匹配、近似匹配等。
+ **实现机制：**
    - 文本分析：通过分析器（Analyzer）对文本进行分词、去除停用词、词干提取等处理，生成倒排索引。
    - 字段类型：适用于文本字段，如 text 类型字段。

```plain
{
  "query": {
    "match": {
      "title": "ES tutorial"
    }
  }
}
```

### 关键区别
+ **匹配精度：**
    - **精准匹配：**查询词必须与字段值完全一致。
    - **全文检索**：查询词会被分析处理，查找相关的文档，不一定要求完全一致。
+ **适用字段类型：**
    - **精准匹配：**通常适用于 keyword 类型的字段。
    - **全文检索：**适用于 text 类型的字段，以及经过文本分析的其他字段。
+ **查询灵活性：**
    - **精准匹配：**查询条件固定，不涉及模糊查询或语义处理。	
    - **全文检索：**支持复杂的查询条件，包括模糊查询、近义词匹配等。

## ES 支持哪些类型的查询
+ 精确匹配，例如 term、exists、term set、 range、prefix、 ids、 wildcard、regexp、 fuzzy等。
+ 全文检索，例如match、match_phrase、multi_match、match_phrase_prefix、query_string 等

## ES有那些分析器
在Elasticsearch中，分词器（Tokenizer）是用于将文本数据分解为单词（Term）的重要概念。分词器是索引和搜索过程中的核心组件，它决定了文本数据如何被分解和处理，从而影响了搜索结果的匹配度和准确性。Elasticsearch支持多种类型的分词器，常见的分词器类型如下

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729522147604-ef9c3775-94b1-4451-88bd-f30c5ebefad2.png)

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729522211261-10d38860-44dd-4c29-9a1e-633777386510.png)

+ Standard Tokenizer
    - Standard Tokenizer是一种最常用的分词器，它将文本数据按照空格和标点符号进行分词，并将单词转换成小写形式。例如：

```plain
GET /_analyze
{
  "tokenizer": "standard",
  "text": "The quick brown fox jumped over the lazy dog."
}
```

    - 这个请求将使用Standard Tokenizer对"The quick brown fox jumped over the lazy dog."进行分解，得到单词序列["the", "quick", "brown", "fox", "jumped", "over", "the", "lazy", "dog"]。
+ Keyword Tokenizer
    - Keyword Tokenizer是一种将整个文本数据作为一个单词进行索引和搜索的分词器，它通常用于精确匹配和过滤。例如：

```plain
GET /_analyze
{
  "tokenizer": "keyword",
  "text": "The quick brown fox jumped over the lazy dog."
}
```

    - 这个请求将使用Keyword Tokenizer对"The quick brown fox jumped over the lazy dog."进行分解，得到单词序列["The quick brown fox jumped over the lazy dog."]。

## Mysql数据同步到Es中的四种方式
### 同步双写
![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729522993907-abf3eb27-4fa1-45a5-a566-5925c353a003.png)

### 异步双写
![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729523028985-b1ef0146-2438-4fcb-abcf-524cd6f4077d.png)

### 数据抽取
![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729523066495-e652f3d9-9702-4abb-81ee-d433349a222c.png)

### 数据订阅
![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729523111196-f45e088d-6335-43c4-b158-43739cedd028.png)

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729523127906-eaba53ee-8a06-4190-8bac-5034b85f8c67.png)

通过阿里巴巴开源的数据同步工具canal订阅mysql的binlog日志到ES,以实现数据增量同步

## 字典树
在 ES 中，字典树（Trie）是一种用于高效存储和检索字符串的数据结构。字典树被广泛用于搜索引擎中，尤其是在处理前缀匹配和自动补全查询时。字典树的主要优点是它能够在 O(k) 的时间内复杂度内找到一个前缀的所有可能匹配项，其中 k 是前缀的长度。

### 字典树的基本结构
字典树是一种树形数据结构，其中每个节点代表一个字符。通过从根节点到叶子节点的路径，可以表示一个完整的单词。每个节点可以包含多个子节点，每个子节点代表一个字符。

###  基本性质
+ 有一个根节点，但根节点无数据
+ 字典树是一种多叉树结构，每个节点可以有多个子节点。每个节点代表一个字符，从根节点到叶子节点的路径表示一个完整的单词
+ 节点中有判断是否为单词的bool型标志位

### <font style="color:rgb(36, 41, 47);">示例</font>
![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729524891962-c7a264bf-872d-40bc-ae02-1529b86417da.png)

<font style="color:rgb(77, 77, 77);">上面这棵树包含的字符串有：cat、dog、deer、pan、panda</font>

### <font style="color:rgb(77, 77, 77);">在 ES 中的应用</font>
+ **前缀查询（Prefix Query）**
    - <font style="color:rgb(77, 77, 77);">字典树用于高效地查找前缀匹配的文档。例如，当用户输入一个查询词的前缀时，ES 可以使用字典树快速找到所有以该前缀开头的词项。</font>
+ **自动补全（Autocomplete）**
    - <font style="color:rgb(77, 77, 77);">字典树在实现自动补全功能时非常有用。当用户输入部分单词时，ES 可以利用字典树快速提供以该部分单词开头的所有可能的完整单词列表。</font>
+ **索引优化**
    - <font style="color:rgb(77, 77, 77);">在构建倒排索引时，ES 可能会使用字典树来优化索引结构，以便更快地进行前缀搜索和匹配。</font>

### 总结
字典树在 ES 中用于高效的前缀匹配和自动补全查询。通过使用字典树，ES 能够在较低的时间复杂度内找到与给定前缀匹配的所有词项，从而提高搜索效率和用户体验。字典树通常基于 FST 实现，以优化存储和检索性能。

## ES的架构是怎样的
ES的架构是分布式的，包括多个节点，每个节点可以是主节点或数据节点。主节点负责集群管理和负载均衡等任务，数据节点负责存储和检索数据。每个节点都可以自由加入或退出集群，具有自动发现和自动平衡功能。ES还具有分片和副本机制，可以将一个索引分成多个部分，每个部分称为一个分片，每个分片可以有多个副本，以提高数据冗余和可用性。

## ES与传统数据库的区别
+ ES与传统数据库最大的不同是，它是基于**全文搜索引擎库Lucene构建**的，因此具有全文搜索、实时搜索、分布式搜索、数据分析等功能，而传统数据库更适合于**事务处理等关系型数据**操作。
+ 传统数据库采用**结构化查询语言（SQL）**进行查询，而ES使用**JSON格式的查询语法**，更加灵活和强大。

## ES的数据如何存储
+ Elasticsearch的数据存储在多个分片中，每个分片存储一部分数据。
+ 每个分片可以有多个副本，分片和副本存储相同的数据，以提高数据冗余和可用性。
+ 数据存储在Lucene索引中，每个索引包含一个或多个分片，每个分片都是一个独立的Lucene索引。
+ 每个文档都存储在一个分片中，每个文档都有一个唯一的ID和一个版本号，以便进行版本控制和冲突检测。

## <font style="color:rgb(0, 0, 0);">Elasticsearch和solr的区别</font>
Elasticsearch（ES）和Solr都是流行的开源搜索引擎，它们都基于Apache Lucene搜索库开发而来，但在一些方面有所不同：

+ **架构：**ES是分布式架构，具有分片和副本机制，支持自动横向扩展，而Solr是基于主从架构，需要手动进行复制和分片。
+ **搜索语法：**ES使用JSON格式的查询语法，而Solr使用XML格式的查询语法。
+ **数据处理：**ES支持实时数据处理和分析，可以通过Logstash和Kibana进行数据采集和展示，而Solr则更专注于搜索和文本分析功能。
+ **社区和生态系统：**ES拥有更大的社区和生态系统，拥有丰富的插件和工具，而Solr则更专注于搜索功能本身。

总的来说，ES更适合处理实时数据、分析、日志等场景，而Solr则更适合于搜索和文本分析场景。

## Elasticsearch中的排序(Sort)有哪些类型？
在Elasticsearch中，排序（Sort）是一种用于排序搜索结果的重要概念。排序可以根据指定的条件对搜索结果进行排序，支持按照文档中的某个字段、某个复合条件等进行排序，从而帮助用户更快地找到所需的文档。Elasticsearch支持多种类型的排序，常见的排序类型如下：

+ Fiels Sort

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729526974483-4fe00d04-57cf-47ba-aa33-64e0fe09d67b.png)

+ Score Sort

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729527018617-0b7121fd-eb38-47c4-82b9-70e3aa18f7a0.png)

+ <font style="color:rgb(1, 1, 1);">Script Sort</font>

![](https://cdn.nlark.com/yuque/0/2024/png/49727441/1729527074922-9e4c6014-ade6-4af2-8231-fcabc739b067.png)

## Elasticsearch中的索引别名(Alias)是什么
在Elasticsearch中，索引别名（Alias）是对一个或多个索引的命名引用，它可以让用户在执行搜索和其他操作时使用别名来代替实际的索引名称。

索引别名的主要作用是提供一个简单的方式来处理索引的版本控制、数据迁移、数据备份等场景，并且可以提供更灵活的搜索和数据管理方式。例如，可以将别名用于分片和负载均衡、跨索引搜索、快速切换索引版本等。